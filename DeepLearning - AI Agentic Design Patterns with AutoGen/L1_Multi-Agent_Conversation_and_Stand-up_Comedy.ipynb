{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81456dd",
   "metadata": {},
   "source": [
    "# Lesson 1: Multi-Agent Conversation and Stand-up Comedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4693467e",
   "metadata": {},
   "source": [
    "Welcome to Lesson 1.\n",
    "\n",
    "To access the `requirements.txt` file and the`utils` modules, please go to the `File` menu and select`Open...`.\n",
    "\n",
    "I hope you enjoy this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2cd282",
   "metadata": {},
   "source": [
    "### ConversableAgent class in Autogen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742cf649",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04d006c1-22fa-40ea-b3e0-d543142e0788",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from utils import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()\n",
    "llm_config = {\"model\": \"gpt-3.5-turbo\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a1c4d",
   "metadata": {},
   "source": [
    "## Define an AutoGen agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fb8c441-c58c-41a8-a54b-5c387afceac5",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 07-12 15:39:23] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    name=\"chatbot\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",  # ALWAYS, NEVER, or PROMPT. ALWAYS will always use the human input as the prompt, NEVER will never use the human input as the prompt, and PROMPT will use the human input as the prompt if it is not empty.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47886b5f-fc7c-431a-8036-cff6e88f85c6",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the tooth go to the dentist by itself? \n",
      "\n",
      "Because it wanted to have a little \"filling\" of its own!\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Tell me a joke about pediatric dentistry.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67f626e9-4cec-40c1-abde-2eff1252b848",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, which joke would you like me to repeat for you?\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(  # generate_reply function does not set internal state of agent\n",
    "    messages=[{\"content\": \"Repeat the joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c98a301",
   "metadata": {},
   "source": [
    "## Conversation\n",
    "\n",
    "Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f109dcb-824e-40d7-8e86-efee42b75f3c",
   "metadata": {
    "height": 285
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 07-12 15:42:23] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 07-12 15:42:23] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"Start the next joke from the punchline of the previous joke.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f71a61",
   "metadata": {},
   "source": [
    "**Note**: You might get a slightly different response (set of jokes) than what is shown in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46a1c6f6-687e-40de-8819-374201cfed9f",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe! Let's do this! So I tried to organize a hide and seek tournament, but it was a total flop. Good news though, I'm unbeaten at it!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "That's impressive, Cathy! I guess you could say you're the \"hide-and-seek champion by default.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, exactly, Joe! I'm the undisputed champion of hide-and-seek... whether I like it or not!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(  # joe starts convo and recipient is cathy\n",
    "    recipient=cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78edc810",
   "metadata": {},
   "source": [
    "## Print some results\n",
    "\n",
    "You can print out:\n",
    "\n",
    "1. Chat history\n",
    "2. Cost\n",
    "3. Summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1169ea24-eadd-4909-8d56-9b7ec5677c66",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': \"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
      "  'role': 'assistant'},\n",
      " {'content': \"Hey Joe! Let's do this! So I tried to organize a hide and seek \"\n",
      "             \"tournament, but it was a total flop. Good news though, I'm \"\n",
      "             'unbeaten at it!',\n",
      "  'role': 'user'},\n",
      " {'content': \"That's impressive, Cathy! I guess you could say you're the \"\n",
      "             '\"hide-and-seek champion by default.\"',\n",
      "  'role': 'assistant'},\n",
      " {'content': \"Haha, exactly, Joe! I'm the undisputed champion of \"\n",
      "             'hide-and-seek... whether I like it or not!',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(chat_result.chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "550267b6-3652-40dc-9997-c5401f6d4c47",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_excluding_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 86,\n",
      "                                                             'cost': 0.00024400000000000002,\n",
      "                                                             'prompt_tokens': 230,\n",
      "                                                             'total_tokens': 316},\n",
      "                                      'total_cost': 0.00024400000000000002},\n",
      " 'usage_including_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 86,\n",
      "                                                             'cost': 0.00024400000000000002,\n",
      "                                                             'prompt_tokens': 230,\n",
      "                                                             'total_tokens': 316},\n",
      "                                      'total_cost': 0.00024400000000000002}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfcf468e-d217-4731-8cb4-3485377230f1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Haha, exactly, Joe! I'm the undisputed champion of hide-and-seek... whether \"\n",
      " 'I like it or not!')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8c6cf8",
   "metadata": {},
   "source": [
    "## Get a better summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1a8fef1-8030-4652-a2d2-1648834f62c2",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe! Let's do this! So I tried to organize a hide and seek tournament, but it was a total flop. Good news though, I'm unbeaten at it!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "That's impressive, Cathy! I guess you could say you're the \"hide-and-seek champion by default.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, exactly, Joe! I'm the undisputed champion of hide-and-seek... whether I like it or not!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\", \n",
    "    max_turns=2, \n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b042de62-bc49-49ee-99f2-4f972e23670b",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cathy jokes about being unbeaten in hide and seek tournaments, leading to '\n",
      " \"Joe's humorous comment about being the champion by default.\")\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300525bd",
   "metadata": {},
   "source": [
    "## Chat Termination\n",
    "\n",
    "Chat can be terminated using a termination conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "044dfd61-7f1d-46d8-9e28-4b2601b43d70",
   "metadata": {
    "height": 336
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 07-12 15:48:27] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 07-12 15:48:27] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],  # boolean function - true/false. If true, conversation ends.\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc49d959-1025-4709-8866-9d4035eaeae7",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe! Why did the scarecrow win an award?\n",
      "\n",
      "Because he was outstanding in his field! \n",
      "\n",
      "Okay, your turn! Give me your best joke!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Haha, that's a good one, Cathy! Here's my joke: Why couldn't the bicycle find its way home?\n",
      "\n",
      "Because it lost its bearings!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, that's a great one, Joe! I love a good pun. Keep 'em coming!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Glad you enjoyed it, Cathy! Here's another one for you: Why did the math book look sad?\n",
      "\n",
      "Because it had too many problems!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, love it, Joe! That one adds up to some good laughs. Thanks for sharing!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "You're welcome, Cathy! Always happy to bring some laughter. If you ever need more jokes, you know where to find me. :)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Thanks, Joe! I appreciate that. You're a jokester in the making. Have a great day!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Thank you, Cathy! You have a great day too. I gotta go.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "846eccbd-efd1-464b-9385-279c19b17c1d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "What's last joke we talked about?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I apologize for the confusion, but as a language model AI, I don't have the capability to remember past interactions once the conversation ends. If you'd like to hear some more jokes or need assistance with anything else, feel free to ask!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "I gotta go.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cathy.send(message=\"What's last joke we talked about?\", recipient=joe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
